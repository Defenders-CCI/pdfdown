% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download_pdf.R
\name{download_pdf}
\alias{download_pdf}
\title{Download a PDF from a URL}
\usage{
download_pdf(url, subd, pause = TRUE)
}
\arguments{
\item{url}{A URL from ECOS to download a document}

\item{subd}{Subdirectory to which the document will be downloaded}

\item{pause}{Whether to pause for 0.5-3 seconds during scraping}
}
\value{
A data.frame with url, destination, success, pdfCheck
}
\description{
Simple function to download a PDF, robustly.
}
\details{
Scraping PDFs from the web can run into little hitches that make
writing a scraper annoying. This simplifies PDF scraping by creating a
dedicated function and support functions to, e.g., test for PDFness. Ensures
URL encoding, handles missing URLs gracefully. The filename is the basename
of the URL with " " replaced with "_".
}
\examples{
\dontrun{
result <- download_pdf("https://goo.gl/I3P3A3", "~/Downloads")
}
}

